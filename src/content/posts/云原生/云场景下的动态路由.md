---
title: 云场景下的动态路由
published: 2025-12-12
description: ""
image: ""
tags: ["云", "网络", "路由"]
category: "云"
draft: false
lang: ""
---

在云计算和容器环境中，路由协议主要解决虚拟网络与物理网络、跨节点/主机通信、服务暴露等问题。​**​ 动态路由的使用显著增强了灵活性和自动化程度。​**​

# 1. ​​OpenStack Neutron 中的动态路由：​​

## ​ 场景 1：路由连接外部网络

- ​**​ 问题：​**​ 虚拟机（VM）需要访问外部网络（如 Internet 或物理数据中心网络）。
- ​**​ 传统方式：​**​ 在提供虚拟路由器服务的节点（Network Node）上配置静态路由或默认路由。
- ​**​ 动态路由场景：​**​
  - ​**​ 原理：​**​ Neutron 允许配置支持 OSPF 或 BGP 的虚拟路由器（通过 ML2/OVN 或其他 L3 Plugin 如 DRaaS）。虚拟路由器与物理路由器/ToR (Top of Rack) 交换路由。
  - ​**​ 应用：​**​ Neutron 虚拟路由器动态向物理网络通告 VM 所在的 Tenant 网络路由（通常是聚合路由）。物理网络也可以向虚拟路由器通告特定路由（如连接其他区域的内部网络或外部出口）。
  - ​**​ 优势：​**​ 自动化网络扩展（新增租户网络自动被通告），无需管理员在物理设备上手动配置静态路由。支持 ​**​VRF Lite​**​ 或其他多租户隔离场景时尤为方便。

## ​ 场景 2：分布式虚拟路由器 ​

- ​**​ 问题：​**​ 集中式网络节点可能成为带宽和性能瓶颈。东西向流量（同一个租户的不同 VM 位于不同计算节点）需要先绕行网络节点。
- ​**​ 原理：​**​OpenStack DVR 将路由功能下放到计算节点。这些节点上的本地路由服务需要一种方式来通告直连在它们上面的 VM 的路由。
- ​**​ 动态路由场景：​**​
  - 在 DVR 中，计算节点的本地路由服务可以运行 OSPF 或 BGP，并与物理网络或 SDN 控制器对等，宣告其上 VM 的 /32 主机路由。
  - 当 VM 迁移时，路由更新随之发生，实现无缝迁移。
- ​**​ 优势：​**​ 消除集中式网络节点瓶颈，提高东西向流量性能。

## 场景 3：高可用虚拟 IP​

- ​**​ 问题：​**​OpenStack Octavia（LBaaS）的后端健康检查切换如何通知网络？
- ​**​ 动态路由场景：​**​
  - ​**​ 原理：​**​ Octavia 的 amphora（负载均衡器实例）或其管理器可以运行 BGP，动态向物理网络或网关宣告/撤销该 VIP 的 /32 路由。例如使用 ​**BGP + ECMP​**​ 实现负载均衡和多活。
  - 当某个 amphora 宕机，它撤销 VIP 路由，流量由其他健康实例宣告的路由引导。
- ​**​ 优势：​**​ 实现基于路由的快速故障切换（通常在秒级），无需依赖 VRRP 的 MAC 切换（受广播域限制且慢）。

# 2. ​Kubernetes 中的动态路由 ​

## 场景 1：Pod 跨节点通信

- ​**​ 问题：​**​Pod 分布在多个 Kubernetes 工作节点上，每个节点运行一个 Pod 网络（覆盖网络或主机路由）。需要一种方式使节点知道哪些 Pod IP 在哪些其他节点上。
- ​**​ 静态方式：​**​ 一些 CNI 插件（如 Flannel host-gw）依赖在节点上静态配置路由，指向其他节点的 Pod 网段。节点多时管理困难。
- ​**​ 动态路由场景（Calico - BGP 模式）：​**​
  - ​**​ 原理：​**​Calico-node（每个节点代理）运行一个轻量级 BGP Daemon（Bird/Frrouting）。节点之间（或通过 ToR 交换机作为 Route Reflector）建立 iBGP/eBGP 对等体关系。
  - 每个节点通告其本地 Pod 网段（或更精确的路由）给邻居。节点学习到其他节点的 Pod 路由后，直接通过节点 IP 进行三层转发。
  - Calico 的 ​**​IPPool​**​ CIDR 被分片到各个节点通告。
- ​**​ 优势：​**​ 自动化 Pod 网络可达性，集群规模扩展性好，故障恢复快（BGP 收敛）。不需要封装隧道开销（对比 VXLAN）。
- ​**​ 插件支持：​**​ Calico (Native BGP)，Cilium (可选 BGP)，kube-router。

## 场景 2：服务暴露（LoadBalancer/Ingress）​

- ​**​ 问题：​**​ 希望外部访问 Service 的 VIP (LoadBalancer Service 的 externalIP 或 Ingress)。
- ​**​ 传统方式：​**​ 依赖云厂商的专有 LB 或配置 NodePort（通过工作节点 IP 访问）。
- ​**​ 动态路由场景：​**​
  - ​**​MetalLB (Layer 2 / BGP 模式)：​**​
    - ​**​ 原理 (BGP 模式)：​**​MetalLB 控制器监控 Kubernetes API，发现有 `LoadBalancer` Service 创建时，分配一个 VIP。MetalLB Speaker Pod（运行于节点）使用 BGP 向物理路由器（ToR 或边界）宣告该 VIP 的 /32 路由（Next-Hop 设为宣告节点 IP 或 ECMP 到一组节点）。
    - 物理网络会将目标为 VIP 的流量路由到宣告节点。MetalLB 通过 ARP/NDP 或 kube-proxy 规则最终将流量负载均衡到后端 Service Pods。
    - ​**​BGP 高级特性：​**​ 可结合 BGP 的 `LOCAL_PREF`，`MED`，`Community` 等属性进行流量控制。
  - ​**​ 云控制器集成：​**​ 云厂商的 CCM 通常使用其云平台的 API 配置外部 LB，但在内部可能广泛使用 BGP 来实现负载均衡器和边界网关之间的路由。
- ​**​ 优势：​**​ 在 Bare Metal K8s 或边缘环境中实现 LoadBalancer Service 类型功能；在混合云中集成更灵活。

## 场景 3：多集群互联 / 服务网格 ​

- ​**​ 问题：​**​ 多个 K8s 集群需要互相访问对方的 Pod 或 Service。
- ​**​ 动态路由场景：​**​
  - ​**​ 原理：​**​ 在每个集群边缘部署支持 BGP 的设备（如路由器、专用虚拟机、SDN 网关、或 K8s 节点运行 BGP）。使用 eBGP/iBGP 在集群之间交换路由。
  - 例如，Cluster A 通过 BGP 向 Cluster B 宣告其 Pod 或 Service CIDR（可能经过聚合）。
  - 使用 ​**​BGP Policy​**​ 控制哪些路由可通告/接收，并应用 NAT/防火墙策略。
- ​**​ 优势：​**​ 比在每个集群中都配置全量静态路由更灵活、易于扩展和管理。

# 3. 总结

- ​​IGP (OSPF/IS-IS)：
  - 场景：​OpenStack DVR 节点间路由通告、较小规模 K8s 集群内节点路由（Calico 也支持 OSPF 但不如 BGP 主流）、OpenStack 内部管理网络的路由。
  - ​ 侧重：​ 区域内拓扑驱动、快速收敛。
- ​​EGP (BGP)：
  - 场景：​​​Kubernetes​​ 中的主力动态路由协议！广泛用于 Calico/Cilium/kube-router 的 ​Pod 跨节点通信 ​ (iBGP/eBGP)，​​MetalLB 暴露 LB Service​​，​ 多集群互联 ​(eBGP/iBGP)，以及 ​​Calico 与物理网络集成 ​。OpenStack​​ 的 Neutron ​​L3 动态路由 ​​（租户网络出口），​Octavia VIP 高可用和负载均衡，O​penStack 多站点互联 ​ (eBGP)，​DVR 的路由通告 ​。
  - 侧重：大规模扩展性，基于策略的精细化控制 ​（路由策略是关键优势）， ​​ 跨自治系统互联 ​（包括物理到虚拟、虚拟到虚拟、跨云）。​
